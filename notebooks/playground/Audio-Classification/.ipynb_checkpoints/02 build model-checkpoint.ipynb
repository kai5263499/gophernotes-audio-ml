{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This builds features for a given mode, either conv or time for CNN or RNN respectively, and stores the resulting pickle file. Then it builds the Keras model and stores that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, LSTM\n",
    "from keras.layers import Dropout, Dense, TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "from python_speech_features import mfcc\n",
    "import pickle\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from cfg import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('instruments.csv')\n",
    "df.set_index('fname', inplace=True)\n",
    "\n",
    "for f in df.index:\n",
    "    rate, signal = wavfile.read('clean/'+f)\n",
    "    df.at[f, 'length'] = signal.shape[0]/rate\n",
    "\n",
    "classes = list(np.unique(df.label))\n",
    "class_dist = df.groupby(['label'])['length'].mean()\n",
    "\n",
    "n_samples = 2 * int(df['length'].sum()/0.1)\n",
    "prob_dist = class_dist/class_dist.sum()\n",
    "choices = np.random.choice(class_dist.index, p=prob_dist)\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.set_title('Class Distribution', y=1.08)\n",
    "#ax.pie(class_dist, labels=class_dist.index, autopct='%1.1f%%',\n",
    "#       shadow=False, startangle=90)\n",
    "#ax.axis('equal')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(mode='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data():\n",
    "    if os.path.isfile(config.p_path):\n",
    "        print('loading existing data for {} model'.format(config.mode))\n",
    "        with open(config.p_path, 'rb') as handle:\n",
    "            tmp = pickle.load(handle)\n",
    "            return tmp\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rand_feat():\n",
    "    tmp = check_data()\n",
    "    if tmp:\n",
    "        return tmp.data[0], tmp.data[1]\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    _min, _max = float('inf'), -float('inf')\n",
    "    for _ in tqdm(range(n_samples)):\n",
    "        rand_class = np.random.choice(class_dist.index, p=prob_dist)\n",
    "        file = np.random.choice(df[df.label==rand_class].index)\n",
    "        rate, wav = wavfile.read('clean/'+file)\n",
    "        label = df.at[file, 'label']\n",
    "        if wav.shape[0] < config.step:\n",
    "            continue\n",
    "        rand_index = np.random.randint(0, wav.shape[0]-config.step)\n",
    "        sample = wav[rand_index:rand_index+config.step]\n",
    "        X_sample = mfcc(sample, rate, numcep=config.nfeat,\n",
    "                        nfilt=config.nfilt, nfft=config.nfft)\n",
    "        _min = min(np.amin(X_sample), _min)\n",
    "        _max = max(np.amax(X_sample), _max)\n",
    "        X.append(X_sample)\n",
    "        y.append(classes.index(label))\n",
    "    config.min = _min\n",
    "    config.max = _max\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = (X - _min) / (_max - _min)\n",
    "    if config.mode == 'conv':\n",
    "        X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "    elif config.mode == 'time':\n",
    "        X = X.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "    y = to_categorical(y, num_classes=10)\n",
    "    config.data = (X, y)\n",
    "    \n",
    "    with open(config.p_path, 'wb') as handle:\n",
    "        pickle.dump(config, handle)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu',\n",
    "                     strides=(1,1), padding='same',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu',\n",
    "                     strides=(1,1), padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu',\n",
    "                     strides=(1,1), padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu',\n",
    "                     strides=(1,1), padding='same'))\n",
    "    model.add(MaxPool2D((2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam', metrics=['acc'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recurrent_model():\n",
    "    # shape of RNN is (n, time, feat)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(32, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(16, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(8, activation='relu')))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21854/21854 [03:16<00:00, 111.47it/s]\n"
     ]
    }
   ],
   "source": [
    "X, y = build_rand_feat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0707 05:36:16.883210 139995566778176 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0707 05:36:16.915966 139995566778176 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0707 05:36:16.923703 139995566778176 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0707 05:36:17.551080 139995566778176 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0707 05:36:17.560863 139995566778176 deprecation.py:506] From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0707 05:36:17.662685 139995566778176 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0707 05:36:17.700722 139995566778176 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 9, 128)            72704     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 9, 128)            131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 128)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 9, 64)             8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 9, 32)             2080      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 9, 16)             528       \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 9, 8)              136       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                730       \n",
      "=================================================================\n",
      "Total params: 216,018\n",
      "Trainable params: 216,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if config.mode == 'conv':\n",
    "    y_flat = np.argmax(y, axis=1)\n",
    "    input_shape = (X.shape[1], X.shape[2], 1)\n",
    "    model = get_conv_model()\n",
    "elif config.mode == 'time':\n",
    "    y_flat = np.argmax(y, axis=1)\n",
    "    input_shape = (X.shape[1], X.shape[2])\n",
    "    model = get_recurrent_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = compute_class_weight('balanced', \n",
    "                                    np.unique(y_flat),\n",
    "                                    y_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(config.model_path, monitor='val_acc',\n",
    "                             verbose=1, mode='max', save_best_only=True,\n",
    "                             save_weights_only=False, period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0707 05:36:18.076245 139995566778176 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19634 samples, validate on 2182 samples\n",
      "Epoch 1/10\n",
      "19634/19634 [==============================] - 18s 935us/step - loss: 1.6928 - acc: 0.3554 - val_loss: 1.2239 - val_acc: 0.5385\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.53850, saving model to models/time.model\n",
      "Epoch 2/10\n",
      "19634/19634 [==============================] - 17s 874us/step - loss: 1.0886 - acc: 0.6039 - val_loss: 0.8479 - val_acc: 0.7136\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.53850 to 0.71357, saving model to models/time.model\n",
      "Epoch 3/10\n",
      "19634/19634 [==============================] - 16s 804us/step - loss: 0.8045 - acc: 0.7201 - val_loss: 0.6753 - val_acc: 0.7544\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.71357 to 0.75435, saving model to models/time.model\n",
      "Epoch 4/10\n",
      "19634/19634 [==============================] - 16s 820us/step - loss: 0.6479 - acc: 0.7775 - val_loss: 0.5536 - val_acc: 0.8084\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.75435 to 0.80843, saving model to models/time.model\n",
      "Epoch 5/10\n",
      "19634/19634 [==============================] - 16s 828us/step - loss: 0.5279 - acc: 0.8215 - val_loss: 0.4985 - val_acc: 0.8355\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.80843 to 0.83547, saving model to models/time.model\n",
      "Epoch 6/10\n",
      "19634/19634 [==============================] - 16s 825us/step - loss: 0.4700 - acc: 0.8428 - val_loss: 0.4241 - val_acc: 0.8556\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.83547 to 0.85564, saving model to models/time.model\n",
      "Epoch 7/10\n",
      "19634/19634 [==============================] - 18s 908us/step - loss: 0.4174 - acc: 0.8617 - val_loss: 0.3610 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.85564 to 0.87214, saving model to models/time.model\n",
      "Epoch 8/10\n",
      "19634/19634 [==============================] - 17s 852us/step - loss: 0.3736 - acc: 0.8749 - val_loss: 0.3213 - val_acc: 0.8937\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.87214 to 0.89368, saving model to models/time.model\n",
      "Epoch 9/10\n",
      "19634/19634 [==============================] - 22s 1ms/step - loss: 0.3444 - acc: 0.8855 - val_loss: 0.3513 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.89368\n",
      "Epoch 10/10\n",
      "19634/19634 [==============================] - 21s 1ms/step - loss: 0.3022 - acc: 0.8994 - val_loss: 0.2991 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.89368 to 0.90147, saving model to models/time.model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f52f70f8a90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=10, batch_size=32, \n",
    "          shuffle=True, validation_split=0.1,\n",
    "         callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(config.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
